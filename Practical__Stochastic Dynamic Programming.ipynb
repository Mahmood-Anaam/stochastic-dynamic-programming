{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "3e92a7d7",
      "metadata": {
        "id": "3e92a7d7"
      },
      "source": [
        "# Practical : Stochastic Dynamic Programming"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "808a9e83",
      "metadata": {
        "id": "808a9e83"
      },
      "source": [
        "### Learning Outcomes:\n",
        "- Markov Decision Process\n",
        "- Stochastic Dynamic Programming"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8ddaaa50",
      "metadata": {
        "id": "8ddaaa50"
      },
      "source": [
        "We will require the following library for this practical (Import all necessary libraries before running the code):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "2a26f74d",
      "metadata": {
        "id": "2a26f74d"
      },
      "outputs": [],
      "source": [
        "import numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8cee083e",
      "metadata": {
        "id": "8cee083e"
      },
      "source": [
        "## Part A: Stochastic Shortest Path"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f8d59aa2",
      "metadata": {
        "id": "f8d59aa2"
      },
      "source": [
        "Recall the shortest path problem in Practical .\n",
        "\n",
        "Tom, who resides in City \"A\", is planning a journey towards City \"H\". Given his limited funds, he has devised a strategic plan to spend each night during his expedition at the abode of a friend. Tom has friends in cities \"B\", \"C\", \"D\", \"E\", \"F\", and \"G\".\n",
        "\n",
        "Tom is mindful of optimizing his energy expenditure and he is aware of the limited distances he can cover each day. On the first day of travel, he can comfortably reach City \"B\", \"C\", or \"D\". On the second day, he can reach City \"E\", \"F\", or \"G\". Ultimately, Tom can reach his destination, City \"H\", on the third day.\n",
        "\n",
        "Particularly, in this practical, we consider a stochastic scenario. The energy consumed during travel is dependent on random factors, including weather, traffic, etc. We can model this randomness with a probability distribution. For simplicity, we will consider a finite and discrete distribution with 3 possible outcomes. To conserve energy and navigate his journey efficiently, Tom must strategically decide where to spend each night along the route. It's imperative for him to consider the energy requirements between cities, which are outlined in the subsequent table. By skillfully selecting his overnight stops, Tom can ensure his expedition is, in average, both cost-effective and successful.\n",
        "\n",
        "| Cities | B | C | D |\n",
        "|:---------:|:---------:|:---------:|:---------:|\n",
        "| **A** | 0.1 -> 120 <br> 0.2 -> 240 <br> 0.7 -> 390 | 0.3 -> 120 <br> 0.2 -> 430 <br> 0.5 -> 320 | 0.6 -> 250 <br> 0.1 -> 140 <br> 0.3 -> 220 |\n",
        "\n",
        "| Cities | E | F | G |\n",
        "|:---------:|:---------:|:---------:|:---------:|\n",
        "| **B** | 0.4 -> 350 <br> 0.1 -> 630 <br> 0.5 -> 700 | 0.2 -> 140 <br> 0.2 -> 900 <br> 0.6 -> 120 | 0.8 -> 400 <br> 0.1 -> 200 <br> 0.1 -> 300 |\n",
        "| **C** | 0.2 -> 150 <br> 0.6 -> 500 <br> 0.2 -> 700 | 0.2 -> 540 <br> 0.2 -> 490 <br> 0.6 -> 330 | 0.3 -> 840 <br> 0.1 -> 120 <br> 0.6 -> 430 |\n",
        "| **D** | 0.3 -> 150 <br> 0.4 -> 130 <br> 0.3 -> 570 | 0.2 -> 600 <br> 0.5 -> 900 <br> 0.3 -> 120 | 0.2 -> 420 <br> 0.1 -> 320 <br> 0.7 -> 930 |\n",
        "\n",
        "| Cities | H |\n",
        "|:---------:|:---------:|\n",
        "| **E** | 0.1 -> 450 <br> 0.4 -> 730 <br> 0.5 -> 940 |\n",
        "| **F** | 0.2 -> 190 <br> 0.5 -> 380 <br> 0.3 -> 740 |\n",
        "| **G** | 0.3 -> 550 <br> 0.6 -> 610 <br> 0.1 -> 720 |\n",
        "\n",
        "\n",
        "The left-hand side of the tables indicate the departure cities, while the top denotes the arrival cities. For example, the \"(0.1, 0.2, 0.7),(120, 240, 390)\" in first line represents that, when Tom drives from City \"A\" to \"B\", it will consumes energy 120 with probability 0.1, and 240 with probability 0.2, and 390 with probability 0.7. Consider the following questions:"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1522b268",
      "metadata": {
        "id": "1522b268"
      },
      "source": [
        "### Q1\n",
        "By inspection of the costs, intuit the optimal path."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8994def5",
      "metadata": {
        "id": "8994def5"
      },
      "source": [
        "### Answer\n",
        "\n",
        "Analyzing the expected energy costs, the optimal path appears to be:\n",
        "\n",
        "1. **A → B:**  Highest probability of low energy cost (0.1 for 120 units, 0.2 for 240 units).\n",
        "2. **B → F:** Lowest expected energy cost with high probability (0.6 for 120 units).\n",
        "3. **F → H:** Lowest expected energy cost with high probability (0.2 for 190 units, 0.5 for 380 units).\n",
        "\n",
        "Therefore, the intuitively optimal path is **A → B → F → H**."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e5d056d2",
      "metadata": {
        "id": "e5d056d2"
      },
      "source": [
        "### Q2\n",
        "Complete the following code to implement the stochastic dynamic programming algorithm for this stochastic shortest path (SPP) problem."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "ab0312df",
      "metadata": {
        "id": "ab0312df"
      },
      "outputs": [],
      "source": [
        "# Define the nodes at each step. Here, the nodes are defined by a dictionary. The keys in this dictionary \"0~3\" represent the\n",
        "# stage, and the values \"0~7\" represent City \"A\"~\"H\", respectively.\n",
        "nodes = {\n",
        "    0: [0],\n",
        "    1: [1,2,3],\n",
        "    2: [4,5,6],\n",
        "    3: [7],\n",
        "}\n",
        "\n",
        "# Define the actions and the corresponding costs between the nodes. The keys in this dictionary \"0~7\" represent City \"A\"~\"H\",\n",
        "# and the values corresponding to each key represent the next city, the probability distribution and the energy cost, respectively.\n",
        "graph = {\n",
        "    0: [(1, [0.1, 0.2, 0.7], [120, 240, 390]), (2, [0.3, 0.2, 0.5], [120, 430, 320]), (3, [0.6, 0.1, 0.3], [250, 140, 220])],\n",
        "    1: [(4, [0.4, 0.1, 0.5], [350, 630, 700]), (5, [0.2, 0.2, 0.6], [140, 900, 120]), (6, [0.8, 0.1, 0.1], [400, 200, 300])],\n",
        "    2: [(4, [0.2, 0.6, 0.2], [150, 500, 700]), (5, [0.2, 0.2, 0.6], [540, 490, 330]), (6, [0.3, 0.1, 0.6], [840, 120, 430])],\n",
        "    3: [(4, [0.3, 0.4, 0.3], [150, 130, 570]), (5, [0.2, 0.5, 0.3], [600, 900, 120]), (6, [0.2, 0.1, 0.7], [420, 320, 930])],\n",
        "    4: [(7, [0.1, 0.4, 0.5], [450, 730, 940])],\n",
        "    5: [(7, [0.2, 0.5, 0.3], [190, 380, 740])],\n",
        "    6: [(7, [0.3, 0.6, 0.1], [550, 610, 720])],\n",
        "    7: [],\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "d02d7140",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d02d7140",
        "outputId": "0653bede-8c41-4cf9-9b1f-65a7bfa3c8cb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Optimal Cost: 1063.0\n",
            "Optimal Path: ['A', 'B', 'F', 'H']\n"
          ]
        }
      ],
      "source": [
        "num_stage = len(nodes)\n",
        "num_nodes = len(graph)\n",
        "value_function = np.zeros(num_nodes)\n",
        "value_function[num_nodes-1] = 0\n",
        "optimal_action = np.zeros(num_nodes)\n",
        "optimal_action[num_nodes-1] = num_nodes-1\n",
        "\n",
        "\n",
        "# Stochastic dynamical programming algorithm\n",
        "for k in range(num_stage-2, -1, -1):\n",
        "    for n in nodes[k]:\n",
        "        values = []\n",
        "        num_action = len(graph[n])\n",
        "        for a in range(num_action):\n",
        "              next_city = graph[n][a][0]\n",
        "              probabilities = graph[n][a][1]\n",
        "              costs = graph[n][a][2]\n",
        "\n",
        "              # Compute the expected value for each action\n",
        "              expected_cost = np.dot(probabilities, costs) + value_function[next_city]\n",
        "              values.append(expected_cost)\n",
        "\n",
        "\n",
        "            ###  END CODE HERE ###\n",
        "\n",
        "        value_function[n] = np.min(values)\n",
        "        optimal_action[n] = graph[n][np.argmin(values)][0]\n",
        "\n",
        "cities = [\"A\", \"B\", \"C\", \"D\", \"E\", \"F\", \"G\", \"H\"]\n",
        "\n",
        "optimal_path_index = nodes[0][:]  # Initialize the optimal path with the starting point\n",
        "optimal_path = [\"A\"]\n",
        "for k in range(1, num_stage):\n",
        "    action = optimal_action[int(optimal_path_index[-1])]\n",
        "    optimal_path_index.append(int(action))\n",
        "    optimal_path.append(cities[int(action)])\n",
        "\n",
        "print('Optimal Cost:', round(value_function[0],2))\n",
        "print('Optimal Path:', optimal_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "22b49e49",
      "metadata": {
        "id": "22b49e49"
      },
      "source": [
        "### Q3\n",
        "Does the optimal path provided by the algorithm match your intuition?"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "43739875",
      "metadata": {
        "id": "43739875"
      },
      "source": [
        "### Answer\n",
        "\n",
        "The optimal path determined by the algorithm (A → B → F → H) aligns perfectly with the initial intuition. The preliminary cost analysis suggested that traveling through City B and then City F would likely yield the lowest expected energy expenditure. The algorithm confirms this, calculating an optimal path with a total expected cost of 1063.0. This strong agreement between the intuitive understanding and the algorithmic solution reinforces the validity of the initial assessment and highlights the effectiveness of the algorithm in identifying the most energy-efficient route for Tom's journey."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c91fa75c",
      "metadata": {
        "id": "c91fa75c"
      },
      "source": [
        "### Q4\n",
        "Does the optimal path match the result obtained in Practical 2? Explain the similarities/differences."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2dcba682",
      "metadata": {
        "id": "2dcba682"
      },
      "source": [
        "### Answer:\n",
        "\n",
        "Yes, the optimal path matches the result obtained in Practical 2. In both cases, the algorithm identified the path **A → B → F → H** as the most cost-effective route.\n",
        "\n",
        "**Similarities:**\n",
        "- Both results found that traveling through cities B and F yields the lowest expected energy cost.\n",
        "- The optimal cost calculated in both approaches is consistent, confirming the reliability of the solution."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9b9fb382",
      "metadata": {
        "id": "9b9fb382"
      },
      "source": [
        "### Q5\n",
        "Modify the probabilities (ensure probabilities sum to 1) or the energy values, and compute the new optimal path and corresponding optimal cost. Discuss the differences observed in comparison to the initial scenario. Consider how these changes in uncertainties impact the outcomes and results."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "50e77f09",
      "metadata": {
        "id": "50e77f09"
      },
      "source": [
        "### Answer:"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9CQRiTfsocFh",
      "metadata": {
        "id": "9CQRiTfsocFh"
      },
      "source": [
        "Let's modify the probabilities and energy values as follows:\n",
        "\n",
        "- **A to B:** Probabilities = [0.2, 0.3, 0.5], Costs = [110, 220, 350]\n",
        "- **A to C:** Probabilities = [0.4, 0.3, 0.3], Costs = [100, 430, 310]\n",
        "- **A to D:** Probabilities = [0.5, 0.3, 0.2], Costs = [230, 120, 210]\n",
        "- **B to F:** Probabilities = [0.1, 0.6, 0.3], Costs = [130, 850, 110]\n",
        "- **F to H:** Probabilities = [0.4, 0.4, 0.2], Costs = [180, 360, 710]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "DRhtz5sHoM9J",
      "metadata": {
        "id": "DRhtz5sHoM9J"
      },
      "outputs": [],
      "source": [
        "# Define the nodes at each step. Here, the nodes are defined by a dictionary. The keys in this dictionary \"0~3\" represent the\n",
        "# stage, and the values \"0~7\" represent City \"A\"~\"H\", respectively.\n",
        "nodes = {\n",
        "    0: [0],\n",
        "    1: [1,2,3],\n",
        "    2: [4,5,6],\n",
        "    3: [7],\n",
        "}\n",
        "\n",
        "\n",
        "# Updated graph with modified probabilities and costs\n",
        "graph = {\n",
        "    0: [(1, [0.2, 0.3, 0.5], [110, 220, 350]), (2, [0.4, 0.3, 0.3], [100, 430, 310]), (3, [0.5, 0.3, 0.2], [230, 120, 210])],\n",
        "    1: [(4, [0.4, 0.1, 0.5], [350, 630, 700]), (5, [0.1, 0.6, 0.3], [130, 850, 110]), (6, [0.8, 0.1, 0.1], [400, 200, 300])],\n",
        "    2: [(4, [0.2, 0.6, 0.2], [150, 500, 700]), (5, [0.2, 0.2, 0.6], [540, 490, 330]), (6, [0.3, 0.1, 0.6], [840, 120, 430])],\n",
        "    3: [(4, [0.3, 0.4, 0.3], [150, 130, 570]), (5, [0.2, 0.5, 0.3], [600, 900, 120]), (6, [0.2, 0.1, 0.7], [420, 320, 930])],\n",
        "    4: [(7, [0.1, 0.4, 0.5], [450, 730, 940])],\n",
        "    5: [(7, [0.4, 0.4, 0.2], [180, 360, 710])],\n",
        "    6: [(7, [0.3, 0.6, 0.1], [550, 610, 720])],\n",
        "    7: [],\n",
        "}\n",
        "\n",
        "# # The output of cell 2 in Q2 is:\n",
        "  # Optimal Cost: 1024.0\n",
        "  # Optimal Path: ['A', 'C', 'F', 'H']\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e4YeiDAUpp0N",
      "metadata": {
        "id": "e4YeiDAUpp0N"
      },
      "source": [
        "### Impact of Modified Probabilities and Energy Values\n",
        "\n",
        "Adjusting the probabilities and energy values resulted in a new optimal path: **A → C → F → H**, with a lower optimal cost of 1024.0.\n",
        "\n",
        "**Key Differences and Insights:**\n",
        "\n",
        "* **Shift in Optimal Path:** The revised optimal path now includes City C instead of City B, demonstrating how alterations in uncertainties and costs can significantly influence the most efficient route.\n",
        "* **Impact of Uncertainty:** This change underscores the importance of considering uncertainties in stochastic dynamic programming.  Variations in probabilities and costs can lead to different optimal solutions, highlighting the need for robust models that account for these fluctuations.\n",
        "* **Decision-Making Implications:** The observed shift in the optimal path emphasizes the sensitivity of decision-making to changes in underlying parameters.  This reinforces the value of incorporating uncertainty analysis into the decision-making process."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1OjjL0KMsLwl",
      "metadata": {
        "id": "1OjjL0KMsLwl"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "841014e5",
      "metadata": {
        "id": "841014e5"
      },
      "source": [
        "## Part B: Stochastic Transition Problem\n",
        "Consider a new SPP scenario. Tom embarks from City \"A\" and is presented with two possible directions: \"East\" and \"West\". Each direction leads to a fork in the road. The \"East\" direction offers paths to City \"B\" and \"C\", while the \"West\" direction connects to City \"D\" and \"E\". Importantly, the possibility exists that one of these paths may be obstructed due to factors like a traffic accident or natural disaster. However, Tom can only ascertain which road is closed once he reaches the fork in the road. The graphical representation of this scenario is provided below:\n",
        "\n",
        "<img src=\"graph.png\" alt=\"Image\" width=\"500\" height=\"500\" />\n",
        "\n",
        "The depicted graph indicates that the paths leading to City \"B\" and \"C\" could potentially be obstructed with probabilities of 0.4 and 0.6, respectively. Similarly, the paths to City \"D\" and \"E\" may experience closures with probabilities of 0.2 and 0.8, respectively. The primary goal is to determine the optimal action to take at each city in this scenario. The corresponding energy costs between the cities are provided below:\n",
        "\n",
        "| Cities | A | B | C | D | E | F | G | H |\n",
        "|:---------:|:---------:|:---------:|:---------:|:---------:|:---------:|:---------:|:---------:|:---------:|\n",
        "| **A** | / | 333 | 282 | 230 | 300 | / | / | / |\n",
        "| **B** | / | / | / | / | / | 553 | 280 | / |\n",
        "| **C** | / | / | / | / | / | 470 | 404 | / |\n",
        "| **D** | / | / | / | / | / | 268 | 606 | / |\n",
        "| **E** | / | / | / | / | / | 807 | 370 | / |\n",
        "| **F** | / | / | / | / | / | / | / | 450 |\n",
        "| **G** | / | / | / | / | / | / | / | 603 |"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "39e165b5",
      "metadata": {
        "id": "39e165b5"
      },
      "source": [
        "### Q6\n",
        "Complete the following code to implement stochastic dynamic programming algorithm for the above stochastic SPP."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "e26b1c74",
      "metadata": {
        "id": "e26b1c74"
      },
      "outputs": [],
      "source": [
        "# Define the nodes at each step. Here the nodes are defined by a dictionary. The keys in this dictionary \"0~3\" represent the\n",
        "# stage, and the values \"0~7\" represent City \"A\"~\"H\", respectively.\n",
        "nodes = {\n",
        "    0: [0],\n",
        "    1: [1,2,3,4],\n",
        "    2: [5,6],\n",
        "    3: [7],\n",
        "}\n",
        "\n",
        "# Define the actions and the corresponding costs between the nodes. The keys in this dictionary \"0~7\" represent City \"A\"~\"H\",\n",
        "# and the values corresponding to each key represent the next city and the energy cost between these two cities, respectively.\n",
        "graph = {\n",
        "    0: [([1,333], [2,282]), ([3,230], [4,300])],\n",
        "    1: [(5,553), (6,280)],\n",
        "    2: [(5,470), (6,404)],\n",
        "    3: [(5,268), (6,606)],\n",
        "    4: [(5,807), (6,370)],\n",
        "    5: [(7,450)],\n",
        "    6: [(7,603)],\n",
        "    7: [],\n",
        "}\n",
        "\n",
        "# Define the transition probability matrix\n",
        "trans_prob = np.array([[0.4,0.6], [0.2,0.8]])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "8238a4ad",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8238a4ad",
        "outputId": "db503a06-206c-4f6a-fcf0-de135ec43802"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Optimal Cost: 1207.6\n",
            "Optimal Action: ['East', 'G', 'F', 'F', 'G', 'H', 'H']\n"
          ]
        }
      ],
      "source": [
        "num_stage = len(nodes)  # The number of stages\n",
        "num_nodes = len(graph)  # The number of nodes\n",
        "value_function = np.zeros(num_nodes)  # Initialize the value function for each node\n",
        "value_function[num_nodes-1] = 0\n",
        "optimal_action = []\n",
        "optimal_path_index = nodes[0]  # Initialize the optimal path with the starting point\n",
        "\n",
        "cities = [\"A\", \"B\", \"C\", \"D\", \"E\", \"F\", \"G\", \"H\"]  # The city nodes\n",
        "directions = [\"East\", \"West\"]\n",
        "\n",
        "# Implement stochastic dynamic programming algorithm\n",
        "for k in range(num_stage - 2, -1, -1):\n",
        "    for n in nodes[k]:\n",
        "        values = []\n",
        "        num_action = len(graph[n])\n",
        "        if n == 0:\n",
        "            for a in range(num_action):\n",
        "                # Compute the expected value for each action at City \"A\"\n",
        "                cost = sum([trans_prob[a, j] * (graph[n][a][j][1] + value_function[graph[n][a][j][0]]) for j in range(len(graph[n][a]))])\n",
        "                values.append(cost)\n",
        "            value_function[n] = min(values)\n",
        "            optimal_action.insert(0, directions[values.index(min(values))])\n",
        "        else:\n",
        "            for a in range(num_action):\n",
        "                # Compute the value for each action in other cities\n",
        "                cost = graph[n][a][1] + value_function[graph[n][a][0]]\n",
        "                values.append(cost)\n",
        "            value_function[n] = min(values)\n",
        "            optimal_action.insert(0, cities[graph[n][values.index(min(values))][0]])\n",
        "\n",
        "# Print the results\n",
        "print('Optimal Cost:', value_function[0])\n",
        "print('Optimal Action:', optimal_action)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b2d9d1a1",
      "metadata": {
        "id": "b2d9d1a1"
      },
      "source": [
        "## Part C: Parking Problem"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "27e58a0e",
      "metadata": {
        "id": "27e58a0e"
      },
      "source": [
        "Let's delve into the parking problem. The parking problem refers to a scenario where you want to optimally park a car in a parking lot while minimizing a cost. Consier the following example: A driver is looking for a\n",
        "park on a street with $N − 1$ car parks. The driver can stop in any car park with cost $c(k)$ and starts looking\n",
        "at car park $k = 0$. If the driver has not stopped by car park $k = N − 1$ then the driver must park at the\n",
        "expensive multi-story car park (terminal state) with cost $C$. Each car park $k$ has an independent random chance of being free\n",
        "with probability $p(k)$. We will consider the following cost functions and probabilities:\n",
        "- (a) $c(k) = N − k,~p(k) = 0.01$\n",
        "- (b) $c(k) = −k^2,~p(k) = 0.01$\n",
        "- (c) $c(k) = k − N,~p(k) = 0.01$\n",
        "- (d) $c(k) = k,~p(k) = \\text{min}(1/k, 0.001)$"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "67eb890d",
      "metadata": {
        "id": "67eb890d"
      },
      "source": [
        "### Q7\n",
        "Consider scenario (a), what do you think will occur? Considering, an average cost, where is the best point to stop?"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c0caf991",
      "metadata": {
        "id": "c0caf991"
      },
      "source": [
        "### Answer:\n",
        "In scenario (a), the parking cost function is given by \\( c(k) = N - k \\), and each parking spot has a constant probability \\( p(k) = 0.01 \\) of being free. This means the cost increases linearly as we move from \\( k = 0 \\) to \\( k = N - 1 \\). Given the low probability of finding a free parking spot, it is more cost-effective to stop at the earliest possible parking spot to avoid the risk of incurring the higher terminal cost \\( C \\). Therefore, the optimal stopping point will be close to \\( k = 0 \\), as parking costs escalate with increasing \\( k \\)."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "593af852",
      "metadata": {
        "id": "593af852"
      },
      "source": [
        "### Q8\n",
        "Discuss the purpose of a terminal state (in the context of a finite horizon)."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "435e098e",
      "metadata": {
        "id": "435e098e"
      },
      "source": [
        "### Answer:\n",
        "\n",
        "The terminal state in the context of a finite horizon represents the scenario where the driver is forced to park at the most expensive parking option after having exhausted all other options. Its primary purpose is to define the worst-case outcome when no free parking spots are available within the feasible searching period. This state ensures that the problem has a defined end point, providing a baseline cost that must be considered when computing optimal policies."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cf6cd45a",
      "metadata": {
        "id": "cf6cd45a"
      },
      "source": [
        "### Q9\n",
        "Write this problem as a Markov Decision Process. (Hint: Identify states and actions)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8269c16f",
      "metadata": {
        "id": "8269c16f"
      },
      "source": [
        "### Answer:\n",
        "\n",
        "The parking problem can be effectively modeled as a Markov Decision Process (MDP) to capture the sequential decision-making aspect inherent in the driver's choices.  Here's a breakdown of the MDP components:\n",
        "\n",
        "**1. States (S):**\n",
        "\n",
        "* Each parking spot `k`, where `k = 0, 1, ..., N-1`, represents a distinct state in the MDP.\n",
        "* The state space `S` comprises all possible parking spots.\n",
        "\n",
        "**2. Actions (A):**\n",
        "\n",
        "* At each state `k`, the driver can choose between two actions:\n",
        "    * **Park (Action 1):** Choose to park at the current spot `k`, incurring an immediate cost of `c(k)` and ending the process.\n",
        "    * **Search (Action 2):** Continue searching for a free spot by moving to the next spot `k+1`, incurring a search cost `s` and facing the uncertainty of finding a free spot.\n",
        "\n",
        "**3. Transition Probabilities (P):**\n",
        "\n",
        "* **P(k+1 | k, Search) = 1 - p(k):**  The probability of transitioning to state `k+1` from state `k` when choosing the \"Search\" action, given that the current spot is not free.\n",
        "* **P(k | k, Search) = p(k):** The probability of remaining in state `k` when choosing the \"Search\" action, given that the current spot is free (process ends with cost `c(k)`).\n",
        "\n",
        "**4. Rewards (R):**\n",
        "\n",
        "* **R(k, Park) = -c(k):** The reward (negative cost) for choosing the \"Park\" action at state `k`.\n",
        "* **R(k, Search) = -s + Expected Future Reward:** The reward for choosing the \"Search\" action, comprising the immediate search cost `-s` and the expected future reward based on the probabilities of finding a free spot at the next state.\n",
        "\n",
        "**5. Value Function (V):**\n",
        "\n",
        "* `V(k)` represents the expected minimum cost (cumulative reward) starting from state `k` and following the optimal policy.\n",
        "\n",
        "**6. Policy (π):**\n",
        "\n",
        "* `π(k)` defines the optimal action to take at state `k`:\n",
        "    * `π(k) = 1 (Park)` if the optimal action is to park at state `k`.\n",
        "    * `π(k) = 0 (Search)` if the optimal action is to continue searching to state `k+1`."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "21eb8813",
      "metadata": {
        "id": "21eb8813"
      },
      "source": [
        "### Q10\n",
        "Complete the following code to implement stochastic dynamic programming algorithm for the parking problem."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "d8127cb6",
      "metadata": {
        "id": "d8127cb6"
      },
      "outputs": [],
      "source": [
        "#Define the stochastic dynamic programming function\n",
        "def stochastic_dynamic_programming(parks_number, search_cost, final_cost, free_probability):\n",
        "    # Create a value function table with the size of the parks_number\n",
        "    value_function = np.zeros(parks_number)\n",
        "    value_function[parks_number-1] = final_cost\n",
        "\n",
        "    # Create a policy table to store the optimal actions\n",
        "    policy = np.zeros(parks_number)\n",
        "\n",
        "        # Iterate over each park, starting from the last one\n",
        "    for k in range(parks_number - 2, -1, -1):\n",
        "        parking_cost = parks_number - k\n",
        "\n",
        "        # Compute the value of parking at the current park\n",
        "        park_value = parking_cost\n",
        "\n",
        "        # Compute the expected cost of searching for another park\n",
        "        search_value = search_cost + (1 - free_probability) * value_function[k + 1] + free_probability * park_value\n",
        "\n",
        "        # Update the value function and policy\n",
        "        if park_value < search_value:\n",
        "            value_function[k] = park_value\n",
        "            policy[k] = 1  # Park here\n",
        "        else:\n",
        "            value_function[k] = search_value\n",
        "            policy[k] = 0  # Search\n",
        "\n",
        "    return value_function, policy"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5a13bb3f",
      "metadata": {
        "id": "5a13bb3f"
      },
      "source": [
        "### Q11\n",
        "Utilising your stochastic dynamic programming function, compute the cost of each state for the above scenarios."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "4bf94af0",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4bf94af0",
        "outputId": "6ea70703-0212-47f2-bdc7-a1622c4f4bd4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Value function: [10.  9.  8.  7.  6.  5.  4.  3.  2. 10.]\n",
            "Optimal policy: [1. 1. 1. 1. 1. 1. 1. 1. 1. 0.]\n"
          ]
        }
      ],
      "source": [
        "parks_number = 10\n",
        "search_cost = 1\n",
        "final_cost = 10\n",
        "free_probability = 0.01\n",
        "\n",
        "value_function, optimal_policy = stochastic_dynamic_programming(parks_number, search_cost, final_cost, free_probability)\n",
        "print(\"Value function:\", value_function)\n",
        "print(\"Optimal policy:\", optimal_policy)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4e23d375",
      "metadata": {
        "id": "4e23d375"
      },
      "source": [
        "### Q12\n",
        "What is the optimal policy for each scenario?"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ed6e766e",
      "metadata": {
        "id": "ed6e766e"
      },
      "source": [
        "### Answer:\n",
        "To determine the optimal policy for each scenario, we need to analyze the given cost functions and probabilities. For each scenario, we’ll derive the policy based on the computed value functions and the nature of the cost functions.\n",
        "\n",
        "1. **Scenario (a) \\( c(k) = N - k \\) and \\( p(k) = 0.01 \\)**:\n",
        "   - **Cost Function**: Costs increase linearly with the park index \\( k \\).\n",
        "   - **Policy**: Park early since costs increase with \\( k \\). The optimal policy will generally be to park at the earliest available spot, as the cost of parking increases linearly. The driver should prefer parking over searching, except possibly when reaching the last few spots, depending on the exact values.\n",
        "\n",
        "2. **Scenario (b) \\( c(k) = -k^2 \\) and \\( p(k) = 0.01 \\)**:\n",
        "   - **Cost Function**: Costs are quadratic and negative, meaning that the cost decreases as \\( k \\) increases.\n",
        "   - **Policy**: Since the cost function is negative and quadratic, the cost decreases with higher \\( k \\). The optimal policy will generally suggest parking at the highest available spot to minimize the cost, except when the final cost is a significant factor.\n",
        "\n",
        "3. **Scenario (c) \\( c(k) = k - N \\) and \\( p(k) = 0.01 \\)**:\n",
        "   - **Cost Function**: Costs increase linearly with \\( k \\), similar to Scenario (a), but offset by \\( -N \\).\n",
        "   - **Policy**: The policy will be similar to Scenario (a) since the cost function linearly increases with \\( k \\). The optimal strategy is to park early to avoid the higher costs associated with higher \\( k \\).\n",
        "\n",
        "4. **Scenario (d) \\( c(k) = k \\) and \\( p(k) = \\text{min}(1/k, 0.001) \\)**:\n",
        "   - **Cost Function**: Costs increase linearly with \\( k \\), but the probability of finding a free spot varies inversely with \\( k \\).\n",
        "   - **Policy**: The policy will depend on how the probability \\( p(k) \\) changes with \\( k \\). Higher \\( k \\) values offer a better probability of finding a free spot but come with higher costs. The optimal policy will balance the probability of finding a free spot with the increasing cost, which might make searching more attractive for intermediate spots and parking at the last spots if the probability is high enough.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "86d836b0",
      "metadata": {
        "id": "86d836b0"
      },
      "source": [
        "### Q13\n",
        "Does the computed optimal control policy align with your intuitive expectations?"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3c183c75",
      "metadata": {
        "id": "3c183c75"
      },
      "source": [
        "### Answer:\n",
        "\n",
        "For Scenario (a) with the cost function \\( c(k) = N - k \\) and a very low probability \\( p(k) = 0.01 \\):\n",
        "\n",
        "   - **Computed Policy**: The policy suggests parking at every park from \\( k = 0 \\) to \\( k = 8 \\) and searching at \\( k = 9 \\).\n",
        "   - **Expectation**: This is consistent with the expectation because the cost of parking increases with \\( k \\), so parking early is optimal. The only deviation is at \\( k = 9 \\), where searching might be preferred due to the final cost being equal to the parking cost.\n",
        "\n",
        "The computed optimal policy indeed aligns with the intuitive expectation for this scenario, as early parking minimizes the cost, and the final spot is used for searching due to its higher cost compared to earlier spots."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "25d6efa1",
      "metadata": {
        "id": "25d6efa1"
      },
      "source": [
        "### Q14\n",
        "Experiment with altering the cost functions and probabilities, and observe the resultant variations in the optimal policy. Discuss how these parameter adjustments influence the determination of the optimal policy."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "eed9f393",
      "metadata": {
        "id": "eed9f393"
      },
      "source": [
        "### Answer:\n",
        "\n",
        "**Experimenting with Cost Functions and Probabilities**\n",
        "\n",
        "**1. Varying Cost Functions:**\n",
        "\n",
        "- **Scenario (a) \\( c(k) = N - k \\) and \\( p(k) = 0.01 \\):**\n",
        "  - **Effect**: Costs increase linearly with \\( k \\). The optimal policy is to park early to minimize the increasing cost.\n",
        "  \n",
        "- **Scenario (b) \\( c(k) = -k^2 \\) and \\( p(k) = 0.01 \\):**\n",
        "  - **Effect**: Costs decrease quadratically with \\( k \\). The optimal policy will favor parking at the highest spot since the cost is lower as \\( k \\) increases.\n",
        "\n",
        "- **Scenario (c) \\( c(k) = k - N \\) and \\( p(k) = 0.01 \\):**\n",
        "  - **Effect**: Costs increase linearly with \\( k \\), offset by \\( -N \\). Similar to Scenario (a), early parking is preferred.\n",
        "\n",
        "- **Scenario (d) \\( c(k) = k \\) and \\( p(k) = \\text{min}(1/k, 0.001) \\):**\n",
        "  - **Effect**: Costs increase linearly with \\( k \\), and the probability of finding a free spot improves with higher \\( k \\). The policy balances between searching and parking based on cost and probability.\n",
        "\n",
        "**2. Varying Probabilities:**\n",
        "\n",
        "- **Low Probability (e.g., \\( p(k) = 0.01 \\)):**\n",
        "  - **Effect**: With a very low probability of finding a free spot, the cost of searching outweighs the potential benefit of finding a free spot. The optimal policy tends to favor parking early to avoid the final cost.\n",
        "\n",
        "- **High Probability (e.g., \\( p(k) = 0.5 \\)):**\n",
        "  - **Effect**: Higher probabilities increase the likelihood of finding a free spot, making searching more attractive. The policy might shift towards searching in intermediate spots and parking only if searching fails or is less beneficial.\n",
        "\n",
        "**3. Experimentation and Analysis:**\n",
        "\n",
        "- **Cost Functions**:\n",
        "  - **Linear Costs**: Policies will favor early parking if costs increase linearly. If costs decrease linearly or quadratically, policies will favor parking at later spots.\n",
        "  - **Quadratic Costs**: With decreasing costs (e.g., \\( -k^2 \\)), policies will shift towards parking at the highest possible spot due to lower costs.\n",
        "\n",
        "- **Probabilities**:\n",
        "  - **Low Probabilities**: Tend to favor early parking since finding a free spot is rare.\n",
        "  - **High Probabilities**: Make searching more viable, shifting the policy towards searching at intermediate spots with better chances of finding a free spot.\n",
        "\n",
        "**Discussion:**\n",
        "\n",
        "- **Cost Influence**: The nature of the cost function directly impacts the optimal policy. Increasing costs lead to early parking, while decreasing costs or lower penalties for final costs may lead to parking later.\n",
        "  \n",
        "- **Probability Influence**: The probability of finding a free spot modifies the balance between searching and parking. Higher probabilities make searching a better option, while lower probabilities make early parking more attractive.\n",
        "\n",
        "In summary, adjusting cost functions and probabilities significantly impacts the determination of the optimal policy, as they directly affect the trade-off between immediate parking costs and the likelihood of finding a free spot while searching."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "841014e5"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
